{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "518ad7fe",
   "metadata": {},
   "source": [
    "## Build a Chatbot\n",
    "\n",
    "https://js.langchain.com/docs/tutorials/chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e1c479",
   "metadata": {},
   "source": [
    "#### Quickstart"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ce2c42",
   "metadata": {},
   "source": [
    "* Instantiate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d806f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Load environment variables\n",
    "import * as dotenv from \"dotenv\";\n",
    "dotenv.config();\n",
    "// Check if the OPENAI_API_KEY environment variable is set\n",
    "if (!process.env.OPENAI_API_KEY) {\n",
    "  throw new Error(\"Missing OPENAI_API_KEY environment variable\");\n",
    "}\n",
    "\n",
    "import { ChatOpenAI } from \"@langchain/openai\";\n",
    "const llm = new ChatOpenAI({\n",
    "  model: \"gpt-4o-mini\",\n",
    "  temperature: 0\n",
    "});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e11e19b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIMessage {\n",
      "  \"id\": \"chatcmpl-BK0uDceHbtihYa1ZYasGxioqBGbXQ\",\n",
      "  \"content\": \"Hi Bob! How can I assist you today?\",\n",
      "  \"additional_kwargs\": {},\n",
      "  \"response_metadata\": {\n",
      "    \"tokenUsage\": {\n",
      "      \"promptTokens\": 10,\n",
      "      \"completionTokens\": 11,\n",
      "      \"totalTokens\": 21\n",
      "    },\n",
      "    \"finish_reason\": \"stop\",\n",
      "    \"model_name\": \"gpt-4o-mini-2024-07-18\",\n",
      "    \"usage\": {\n",
      "      \"prompt_tokens\": 10,\n",
      "      \"completion_tokens\": 11,\n",
      "      \"total_tokens\": 21,\n",
      "      \"prompt_tokens_details\": {\n",
      "        \"cached_tokens\": 0,\n",
      "        \"audio_tokens\": 0\n",
      "      },\n",
      "      \"completion_tokens_details\": {\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "      }\n",
      "    },\n",
      "    \"system_fingerprint\": \"fp_b376dfbbd5\"\n",
      "  },\n",
      "  \"tool_calls\": [],\n",
      "  \"invalid_tool_calls\": [],\n",
      "  \"usage_metadata\": {\n",
      "    \"output_tokens\": 11,\n",
      "    \"input_tokens\": 10,\n",
      "    \"total_tokens\": 21,\n",
      "    \"input_token_details\": {\n",
      "      \"audio\": 0,\n",
      "      \"cache_read\": 0\n",
      "    },\n",
      "    \"output_token_details\": {\n",
      "      \"audio\": 0,\n",
      "      \"reasoning\": 0\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "await llm.invoke([{ role: \"user\", content: \"Hi im bob\" }]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439342b2",
   "metadata": {},
   "source": [
    "The model on its own does not have any concept of state. For example, if you ask a followup question:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd4b8651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIMessage {\n",
      "  \"id\": \"chatcmpl-BK0uDMip3uETmP4T6mpXLoq0wule7\",\n",
      "  \"content\": \"I'm sorry, but I don't have access to personal information about you unless you've shared it in this conversation. How can I assist you today?\",\n",
      "  \"additional_kwargs\": {},\n",
      "  \"response_metadata\": {\n",
      "    \"tokenUsage\": {\n",
      "      \"promptTokens\": 10,\n",
      "      \"completionTokens\": 29,\n",
      "      \"totalTokens\": 39\n",
      "    },\n",
      "    \"finish_reason\": \"stop\",\n",
      "    \"model_name\": \"gpt-4o-mini-2024-07-18\",\n",
      "    \"usage\": {\n",
      "      \"prompt_tokens\": 10,\n",
      "      \"completion_tokens\": 29,\n",
      "      \"total_tokens\": 39,\n",
      "      \"prompt_tokens_details\": {\n",
      "        \"cached_tokens\": 0,\n",
      "        \"audio_tokens\": 0\n",
      "      },\n",
      "      \"completion_tokens_details\": {\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "      }\n",
      "    },\n",
      "    \"system_fingerprint\": \"fp_b376dfbbd5\"\n",
      "  },\n",
      "  \"tool_calls\": [],\n",
      "  \"invalid_tool_calls\": [],\n",
      "  \"usage_metadata\": {\n",
      "    \"output_tokens\": 29,\n",
      "    \"input_tokens\": 10,\n",
      "    \"total_tokens\": 39,\n",
      "    \"input_token_details\": {\n",
      "      \"audio\": 0,\n",
      "      \"cache_read\": 0\n",
      "    },\n",
      "    \"output_token_details\": {\n",
      "      \"audio\": 0,\n",
      "      \"reasoning\": 0\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "await llm.invoke([{ role: \"user\", content: \"Whats my name\" }]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d774edb4",
   "metadata": {},
   "source": [
    "To get around this, we need to pass the entire conversation history into the model. Let’s see what happens when we do that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b17c166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIMessage {\n",
      "  \"id\": \"chatcmpl-BK0uECRhnsB2jx0Ucd9ZQvbKU6QvD\",\n",
      "  \"content\": \"Your name is Bob! How can I help you today?\",\n",
      "  \"additional_kwargs\": {},\n",
      "  \"response_metadata\": {\n",
      "    \"tokenUsage\": {\n",
      "      \"promptTokens\": 33,\n",
      "      \"completionTokens\": 13,\n",
      "      \"totalTokens\": 46\n",
      "    },\n",
      "    \"finish_reason\": \"stop\",\n",
      "    \"model_name\": \"gpt-4o-mini-2024-07-18\",\n",
      "    \"usage\": {\n",
      "      \"prompt_tokens\": 33,\n",
      "      \"completion_tokens\": 13,\n",
      "      \"total_tokens\": 46,\n",
      "      \"prompt_tokens_details\": {\n",
      "        \"cached_tokens\": 0,\n",
      "        \"audio_tokens\": 0\n",
      "      },\n",
      "      \"completion_tokens_details\": {\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "      }\n",
      "    },\n",
      "    \"system_fingerprint\": \"fp_b376dfbbd5\"\n",
      "  },\n",
      "  \"tool_calls\": [],\n",
      "  \"invalid_tool_calls\": [],\n",
      "  \"usage_metadata\": {\n",
      "    \"output_tokens\": 13,\n",
      "    \"input_tokens\": 33,\n",
      "    \"total_tokens\": 46,\n",
      "    \"input_token_details\": {\n",
      "      \"audio\": 0,\n",
      "      \"cache_read\": 0\n",
      "    },\n",
      "    \"output_token_details\": {\n",
      "      \"audio\": 0,\n",
      "      \"reasoning\": 0\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "await llm.invoke([\n",
    "  { role: \"user\", content: \"Hi! I'm Bob\" },\n",
    "  { role: \"assistant\", content: \"Hello Bob! How can I assist you today?\" },\n",
    "  { role: \"user\", content: \"What's my name?\" },\n",
    "]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58dac7f",
   "metadata": {},
   "source": [
    "And now we can see that we get a good response!\n",
    "\n",
    "This is the basic idea underpinning a chatbot’s ability to interact conversationally. So how do we best implement this?\n",
    "\n",
    "#### Message persistence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5c60165",
   "metadata": {},
   "outputs": [],
   "source": [
    "import {\n",
    "  START,\n",
    "  END,\n",
    "  MessagesAnnotation,\n",
    "  StateGraph,\n",
    "  MemorySaver,\n",
    "} from \"@langchain/langgraph\";\n",
    "\n",
    "// Define the function that calls the model\n",
    "const callModel = async (state: typeof MessagesAnnotation.State) => {\n",
    "  const response = await llm.invoke(state.messages);\n",
    "  return { messages: response };\n",
    "};\n",
    "\n",
    "// Define a new graph\n",
    "const workflow = new StateGraph(MessagesAnnotation)\n",
    "  // Define the node and edge\n",
    "  .addNode(\"model\", callModel)\n",
    "  .addEdge(START, \"model\")\n",
    "  .addEdge(\"model\", END);\n",
    "\n",
    "// Add memory\n",
    "const memory = new MemorySaver();\n",
    "const app = workflow.compile({ checkpointer: memory });"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "93caaf6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { v4 as uuidv4 } from \"uuid\";\n",
    "\n",
    "const config = { configurable: { thread_id: uuidv4() } };"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77538935",
   "metadata": {},
   "source": [
    "This enables us to support multiple conversation threads with a single application, a common requirement when your application has multiple users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b7f9fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIMessage {\n",
      "  \"id\": \"chatcmpl-BK0uFjJyBtu8RIRoXYx0Mtlgk0vPU\",\n",
      "  \"content\": \"Hi Bob! How can I assist you today?\",\n",
      "  \"additional_kwargs\": {},\n",
      "  \"response_metadata\": {\n",
      "    \"tokenUsage\": {\n",
      "      \"promptTokens\": 12,\n",
      "      \"completionTokens\": 11,\n",
      "      \"totalTokens\": 23\n",
      "    },\n",
      "    \"finish_reason\": \"stop\",\n",
      "    \"model_name\": \"gpt-4o-mini-2024-07-18\",\n",
      "    \"usage\": {\n",
      "      \"prompt_tokens\": 12,\n",
      "      \"completion_tokens\": 11,\n",
      "      \"total_tokens\": 23,\n",
      "      \"prompt_tokens_details\": {\n",
      "        \"cached_tokens\": 0,\n",
      "        \"audio_tokens\": 0\n",
      "      },\n",
      "      \"completion_tokens_details\": {\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "      }\n",
      "    },\n",
      "    \"system_fingerprint\": \"fp_b376dfbbd5\"\n",
      "  },\n",
      "  \"tool_calls\": [],\n",
      "  \"invalid_tool_calls\": [],\n",
      "  \"usage_metadata\": {\n",
      "    \"output_tokens\": 11,\n",
      "    \"input_tokens\": 12,\n",
      "    \"total_tokens\": 23,\n",
      "    \"input_token_details\": {\n",
      "      \"audio\": 0,\n",
      "      \"cache_read\": 0\n",
      "    },\n",
      "    \"output_token_details\": {\n",
      "      \"audio\": 0,\n",
      "      \"reasoning\": 0\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "const input = [\n",
    "  {\n",
    "    role: \"user\",\n",
    "    content: \"Hi! I'm Bob.\",\n",
    "  },\n",
    "];\n",
    "const output = await app.invoke({ messages: input }, config);\n",
    "// The output contains all messages in the state.\n",
    "// This will log the last message in the conversation.\n",
    "console.log(output.messages[output.messages.length - 1]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "858a5ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIMessage {\n",
      "  \"id\": \"chatcmpl-BK0zcsL9rkhawo6I1LOoSkoc1DYzl\",\n",
      "  \"content\": \"Your name is Bob! How can I help you today, Bob?\",\n",
      "  \"additional_kwargs\": {},\n",
      "  \"response_metadata\": {\n",
      "    \"tokenUsage\": {\n",
      "      \"promptTokens\": 34,\n",
      "      \"completionTokens\": 15,\n",
      "      \"totalTokens\": 49\n",
      "    },\n",
      "    \"finish_reason\": \"stop\",\n",
      "    \"model_name\": \"gpt-4o-mini-2024-07-18\",\n",
      "    \"usage\": {\n",
      "      \"prompt_tokens\": 34,\n",
      "      \"completion_tokens\": 15,\n",
      "      \"total_tokens\": 49,\n",
      "      \"prompt_tokens_details\": {\n",
      "        \"cached_tokens\": 0,\n",
      "        \"audio_tokens\": 0\n",
      "      },\n",
      "      \"completion_tokens_details\": {\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "      }\n",
      "    },\n",
      "    \"system_fingerprint\": \"fp_b376dfbbd5\"\n",
      "  },\n",
      "  \"tool_calls\": [],\n",
      "  \"invalid_tool_calls\": [],\n",
      "  \"usage_metadata\": {\n",
      "    \"output_tokens\": 15,\n",
      "    \"input_tokens\": 34,\n",
      "    \"total_tokens\": 49,\n",
      "    \"input_token_details\": {\n",
      "      \"audio\": 0,\n",
      "      \"cache_read\": 0\n",
      "    },\n",
      "    \"output_token_details\": {\n",
      "      \"audio\": 0,\n",
      "      \"reasoning\": 0\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "const input2 = [\n",
    "  {\n",
    "    role: \"user\",\n",
    "    content: \"What's my name?\",\n",
    "  },\n",
    "];\n",
    "const output2 = await app.invoke({ messages: input2 }, config);\n",
    "console.log(output2.messages[output2.messages.length - 1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824864dd",
   "metadata": {},
   "source": [
    "Great! Our chatbot now remembers things about us. If we change the config to reference a different thread_id, we can see that it starts the conversation fresh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bfa1bc4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIMessage {\n",
      "  \"id\": \"chatcmpl-BK11VBuuQ2E6dPaykDbs2sCuXsj2Q\",\n",
      "  \"content\": \"I'm sorry, but I don't have access to personal information about you unless you've shared it in this conversation. How can I assist you today?\",\n",
      "  \"additional_kwargs\": {},\n",
      "  \"response_metadata\": {\n",
      "    \"tokenUsage\": {\n",
      "      \"promptTokens\": 11,\n",
      "      \"completionTokens\": 29,\n",
      "      \"totalTokens\": 40\n",
      "    },\n",
      "    \"finish_reason\": \"stop\",\n",
      "    \"model_name\": \"gpt-4o-mini-2024-07-18\",\n",
      "    \"usage\": {\n",
      "      \"prompt_tokens\": 11,\n",
      "      \"completion_tokens\": 29,\n",
      "      \"total_tokens\": 40,\n",
      "      \"prompt_tokens_details\": {\n",
      "        \"cached_tokens\": 0,\n",
      "        \"audio_tokens\": 0\n",
      "      },\n",
      "      \"completion_tokens_details\": {\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "      }\n",
      "    },\n",
      "    \"system_fingerprint\": \"fp_b376dfbbd5\"\n",
      "  },\n",
      "  \"tool_calls\": [],\n",
      "  \"invalid_tool_calls\": [],\n",
      "  \"usage_metadata\": {\n",
      "    \"output_tokens\": 29,\n",
      "    \"input_tokens\": 11,\n",
      "    \"total_tokens\": 40,\n",
      "    \"input_token_details\": {\n",
      "      \"audio\": 0,\n",
      "      \"cache_read\": 0\n",
      "    },\n",
      "    \"output_token_details\": {\n",
      "      \"audio\": 0,\n",
      "      \"reasoning\": 0\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "const config2 = { configurable: { thread_id: uuidv4() } };\n",
    "const input3 = [\n",
    "  {\n",
    "    role: \"user\",\n",
    "    content: \"What's my name?\",\n",
    "  },\n",
    "];\n",
    "const output3 = await app.invoke({ messages: input3 }, config2);\n",
    "console.log(output3.messages[output3.messages.length - 1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef38a19",
   "metadata": {},
   "source": [
    "However, we can always go back to the original conversation (since we are persisting it in a database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "82be2ff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fetch failed\n",
      "\n",
      "Context: trace=523b73ef-e356-4726-83a7-c622bf657ddc,id=523b73ef-e356-4726-83a7-c622bf657ddc; trace=523b73ef-e356-4726-83a7-c622bf657ddc,id=10ef5a1c-7b8e-487f-957c-6f7821628a1d; trace=523b73ef-e356-4726-83a7-c622bf657ddc,id=a7f05a3d-1203-4a75-99b2-21b481e5b1dc; trace=523b73ef-e356-4726-83a7-c622bf657ddc,id=2600a2a6-d006-413c-a824-6f286e6f888b; trace=523b73ef-e356-4726-83a7-c622bf657ddc,id=3e5261b8-b6b3-482d-af89-e4da579a0bd1; trace=523b73ef-e356-4726-83a7-c622bf657ddc,id=9a250aa1-1c5d-4075-bfc8-a2bc347ea730\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIMessage {\n",
      "  \"id\": \"chatcmpl-BK128fk79HCLwaLKDOQpPH7VBDXST\",\n",
      "  \"content\": \"Your name is Bob. Is there anything else you'd like to talk about?\",\n",
      "  \"additional_kwargs\": {},\n",
      "  \"response_metadata\": {\n",
      "    \"tokenUsage\": {\n",
      "      \"promptTokens\": 60,\n",
      "      \"completionTokens\": 16,\n",
      "      \"totalTokens\": 76\n",
      "    },\n",
      "    \"finish_reason\": \"stop\",\n",
      "    \"model_name\": \"gpt-4o-mini-2024-07-18\",\n",
      "    \"usage\": {\n",
      "      \"prompt_tokens\": 60,\n",
      "      \"completion_tokens\": 16,\n",
      "      \"total_tokens\": 76,\n",
      "      \"prompt_tokens_details\": {\n",
      "        \"cached_tokens\": 0,\n",
      "        \"audio_tokens\": 0\n",
      "      },\n",
      "      \"completion_tokens_details\": {\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "      }\n",
      "    },\n",
      "    \"system_fingerprint\": \"fp_b376dfbbd5\"\n",
      "  },\n",
      "  \"tool_calls\": [],\n",
      "  \"invalid_tool_calls\": [],\n",
      "  \"usage_metadata\": {\n",
      "    \"output_tokens\": 16,\n",
      "    \"input_tokens\": 60,\n",
      "    \"total_tokens\": 76,\n",
      "    \"input_token_details\": {\n",
      "      \"audio\": 0,\n",
      "      \"cache_read\": 0\n",
      "    },\n",
      "    \"output_token_details\": {\n",
      "      \"audio\": 0,\n",
      "      \"reasoning\": 0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "AIMessage {\n",
      "  \"id\": \"chatcmpl-BK129cMueycalbKMY9lY2vQYZP76l\",\n",
      "  \"content\": \"Your name is Bob. Is there anything else you'd like to talk about?\",\n",
      "  \"additional_kwargs\": {},\n",
      "  \"response_metadata\": {\n",
      "    \"tokenUsage\": {\n",
      "      \"promptTokens\": 68,\n",
      "      \"completionTokens\": 16,\n",
      "      \"totalTokens\": 84\n",
      "    },\n",
      "    \"finish_reason\": \"stop\",\n",
      "    \"model_name\": \"gpt-4o-mini-2024-07-18\",\n",
      "    \"usage\": {\n",
      "      \"prompt_tokens\": 68,\n",
      "      \"completion_tokens\": 16,\n",
      "      \"total_tokens\": 84,\n",
      "      \"prompt_tokens_details\": {\n",
      "        \"cached_tokens\": 0,\n",
      "        \"audio_tokens\": 0\n",
      "      },\n",
      "      \"completion_tokens_details\": {\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "      }\n",
      "    },\n",
      "    \"system_fingerprint\": \"fp_b376dfbbd5\"\n",
      "  },\n",
      "  \"tool_calls\": [],\n",
      "  \"invalid_tool_calls\": [],\n",
      "  \"usage_metadata\": {\n",
      "    \"output_tokens\": 16,\n",
      "    \"input_tokens\": 68,\n",
      "    \"total_tokens\": 84,\n",
      "    \"input_token_details\": {\n",
      "      \"audio\": 0,\n",
      "      \"cache_read\": 0\n",
      "    },\n",
      "    \"output_token_details\": {\n",
      "      \"audio\": 0,\n",
      "      \"reasoning\": 0\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "const output4 = await app.invoke({ messages: input2 }, config);\n",
    "console.log(output4.messages[output4.messages.length - 1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b11029f",
   "metadata": {},
   "source": [
    "This is how we can support a chatbot having conversations with many users!\n",
    "\n",
    "Right now, all we’ve done is add a simple persistence layer around the model. We can start to make the more complicated and personalized by adding in a prompt template."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aef1762",
   "metadata": {},
   "source": [
    "#### Prompt templates"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TypeScript",
   "language": "typescript",
   "name": "tslab"
  },
  "language_info": {
   "codemirror_mode": {
    "mode": "typescript",
    "name": "javascript",
    "typescript": true
   },
   "file_extension": ".ts",
   "mimetype": "text/typescript",
   "name": "typescript",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
