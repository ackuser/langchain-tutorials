{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "518ad7fe",
   "metadata": {},
   "source": [
    "## Classify Text into Labels\n",
    "\n",
    "https://js.langchain.com/docs/tutorials/classification/\n",
    "\n",
    "\n",
    "Tagging means labeling a document with classes such as:\n",
    "\n",
    "- sentiment\n",
    "- language\n",
    "- style (formal, informal etc.)\n",
    "- covered topics\n",
    "- political tendency\n",
    "\n",
    "![Overview](../../assets/images/classification_workflow.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e1c479",
   "metadata": {},
   "source": [
    "#### Quickstart"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ce2c42",
   "metadata": {},
   "source": [
    "* Instantiate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d806f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Load environment variables\n",
    "import * as dotenv from \"dotenv\";\n",
    "dotenv.config();\n",
    "// Check if the OPENAI_API_KEY environment variable is set\n",
    "if (!process.env.OPENAI_API_KEY) {\n",
    "  throw new Error(\"Missing OPENAI_API_KEY environment variable\");\n",
    "}\n",
    "\n",
    "import { ChatOpenAI } from \"@langchain/openai\";\n",
    "const llm = new ChatOpenAI({\n",
    "  model: \"gpt-4o-mini\",\n",
    "  temperature: 0\n",
    "});"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439342b2",
   "metadata": {},
   "source": [
    "* Letâ€™s specify a Zod schema with a few properties and their expected type in our schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd4b8651",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { ChatPromptTemplate } from \"@langchain/core/prompts\";\n",
    "import { z } from \"zod\";\n",
    "\n",
    "const taggingPrompt = ChatPromptTemplate.fromTemplate(\n",
    "  `Extract the desired information from the following passage.\n",
    "\n",
    "Only extract the properties mentioned in the 'Classification' function.\n",
    "\n",
    "Passage:\n",
    "{input}\n",
    "`\n",
    ");\n",
    "\n",
    "const classificationSchema = z.object({\n",
    "  sentiment: z.string().describe(\"The sentiment of the text\"),\n",
    "  aggressiveness: z\n",
    "    .number()\n",
    "    .int()\n",
    "    .describe(\"How aggressive the text is on a scale from 1 to 10\"),\n",
    "  language: z.string().describe(\"The language the text is written in\"),\n",
    "});\n",
    "\n",
    "// Name is optional, but gives the models more clues as to what your schema represents\n",
    "const llmWihStructuredOutput = llm.withStructuredOutput(classificationSchema, {\n",
    "  name: \"extractor\",\n",
    "});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b17c166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ sentiment: 'positive', aggressiveness: 1, language: 'Spanish' }\n"
     ]
    }
   ],
   "source": [
    "const prompt1 = await taggingPrompt.invoke({\n",
    "    input:\n",
    "      \"Estoy increiblemente contento de haberte conocido! Creo que seremos muy buenos amigos!\",\n",
    "  });\n",
    "  await llmWihStructuredOutput.invoke(prompt1);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58dac7f",
   "metadata": {},
   "source": [
    "#### Finer control\n",
    "\n",
    "Specifically, we can define:\n",
    "\n",
    "- possible values for each property\n",
    "- description to make sure that the model understands the property\n",
    "- required properties to be returned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5c60165",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { z } from \"zod\";\n",
    "\n",
    "const classificationSchema2 = z.object({\n",
    "  sentiment: z\n",
    "    .enum([\"happy\", \"neutral\", \"sad\"])\n",
    "    .describe(\"The sentiment of the text\"),\n",
    "  aggressiveness: z\n",
    "    .number()\n",
    "    .int()\n",
    "    .describe(\n",
    "      \"describes how aggressive the statement is on a scale from 1 to 5. The higher the number the more aggressive\"\n",
    "    ),\n",
    "  language: z\n",
    "    .enum([\"spanish\", \"english\", \"french\", \"german\", \"italian\"])\n",
    "    .describe(\"The language the text is written in\"),\n",
    "});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93caaf6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "const taggingPrompt2 = ChatPromptTemplate.fromTemplate(\n",
    "    `Extract the desired information from the following passage.\n",
    "  \n",
    "  Only extract the properties mentioned in the 'Classification' function.\n",
    "  \n",
    "  Passage:\n",
    "  {input}\n",
    "  `\n",
    "  );\n",
    "  \n",
    "  const llmWithStructuredOutput2 = llm.withStructuredOutput(\n",
    "    classificationSchema2,\n",
    "    { name: \"extractor\" }\n",
    "  );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b7f9fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ sentiment: 'happy', aggressiveness: 1, language: 'spanish' }\n"
     ]
    }
   ],
   "source": [
    "const prompt2 = await taggingPrompt2.invoke({\n",
    "    input:\n",
    "      \"Estoy increiblemente contento de haberte conocido! Creo que seremos muy buenos amigos!\",\n",
    "  });\n",
    "  await llmWithStructuredOutput2.invoke(prompt2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "858a5ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ sentiment: 'sad', aggressiveness: 5, language: 'spanish' }\n"
     ]
    }
   ],
   "source": [
    "const prompt3 = await taggingPrompt2.invoke({\n",
    "  input: \"Estoy muy enojado con vos! Te voy a dar tu merecido!\",\n",
    "});\n",
    "await llmWithStructuredOutput2.invoke(prompt3);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfa1bc4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ sentiment: 'happy', aggressiveness: 1, language: 'english' }\n"
     ]
    }
   ],
   "source": [
    "const prompt4 = await taggingPrompt2.invoke({\n",
    "    input: \"Weather is ok here, I can go outside without much more than a coat\",\n",
    "  });\n",
    "  await llmWithStructuredOutput2.invoke(prompt4);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TypeScript",
   "language": "typescript",
   "name": "tslab"
  },
  "language_info": {
   "codemirror_mode": {
    "mode": "typescript",
    "name": "javascript",
    "typescript": true
   },
   "file_extension": ".ts",
   "mimetype": "text/typescript",
   "name": "typescript",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
