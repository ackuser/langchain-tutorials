{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "518ad7fe",
   "metadata": {},
   "source": [
    "## Build an Extraction Chain\n",
    "\n",
    "https://js.langchain.com/docs/tutorials/extraction/\n",
    "\n",
    "#### The Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d806f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { z } from \"zod\";\n",
    "\n",
    "const personSchema = z.object({\n",
    "  name: z.optional(z.string()).describe(\"The name of the person\"),\n",
    "  hair_color: z\n",
    "    .optional(z.string())\n",
    "    .describe(\"The color of the person's hair if known\"),\n",
    "  height_in_meters: z\n",
    "    .optional(z.string())\n",
    "    .describe(\"Height measured in meters\"),\n",
    "});"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439342b2",
   "metadata": {},
   "source": [
    "#### The Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd4b8651",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { ChatPromptTemplate } from \"@langchain/core/prompts\";\n",
    "\n",
    "// Define a custom prompt to provide instructions and any additional context.\n",
    "// 1) You can add examples into the prompt template to improve extraction quality\n",
    "// 2) Introduce additional parameters to take context into account (e.g., include metadata\n",
    "//    about the document from which the text was extracted.)\n",
    "const promptTemplate = ChatPromptTemplate.fromMessages([\n",
    "  [\n",
    "    \"system\",\n",
    "    `You are an expert extraction algorithm.\n",
    "Only extract relevant information from the text.\n",
    "If you do not know the value of an attribute asked to extract,\n",
    "return null for the attribute's value.`,\n",
    "  ],\n",
    "  // Please see the how-to about improving performance with\n",
    "  // reference examples.\n",
    "  // [\"placeholder\", \"{examples}\"],\n",
    "  [\"human\", \"{text}\"],\n",
    "]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58dac7f",
   "metadata": {},
   "source": [
    "* Instantiate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5c60165",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Load environment variables\n",
    "import * as dotenv from \"dotenv\";\n",
    "dotenv.config();\n",
    "// Check if the OPENAI_API_KEY environment variable is set\n",
    "if (!process.env.OPENAI_API_KEY) {\n",
    "  throw new Error(\"Missing OPENAI_API_KEY environment variable\");\n",
    "}\n",
    "\n",
    "import { ChatOpenAI } from \"@langchain/openai\";\n",
    "const llm = new ChatOpenAI({\n",
    "  model: \"gpt-4o-mini\",\n",
    "  temperature: 0\n",
    "});"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2539f3",
   "metadata": {},
   "source": [
    "*  We enable structured output by creating a new object with the .withStructuredOutput method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b7f9fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "const structured_llm = llm.withStructuredOutput(personSchema);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8feead5",
   "metadata": {},
   "source": [
    "* We can then invoke it normally:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "858a5ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fetch failed\n",
      "\n",
      "Context: trace=fa360d9a-0a0e-47bb-8e5c-5ce714eb57a9,id=fa360d9a-0a0e-47bb-8e5c-5ce714eb57a9; trace=a8cc7dff-7390-498d-9187-9c26079e303a,id=a8cc7dff-7390-498d-9187-9c26079e303a; trace=a8cc7dff-7390-498d-9187-9c26079e303a,id=4ceaf427-fe2e-4c03-bc44-f4e0d381b783\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ name: 'Alan Smith', hair_color: 'blond', height_in_meters: '1.83' }\n"
     ]
    }
   ],
   "source": [
    "const prompt = await promptTemplate.invoke({\n",
    "  text: \"Alan Smith is 6 feet tall and has blond hair.\",\n",
    "});\n",
    "await structured_llm.invoke(prompt);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb35128",
   "metadata": {},
   "source": [
    "#### Multiple Entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4e8c461",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { z } from \"zod\";\n",
    "\n",
    "const person = z.object({\n",
    "  name: z.optional(z.string()).describe(\"The name of the person\"),\n",
    "  hair_color: z\n",
    "    .optional(z.string())\n",
    "    .describe(\"The color of the person's hair if known\"),\n",
    "  height_in_meters: z.number().nullish().describe(\"Height measured in meters\"),\n",
    "});\n",
    "\n",
    "const dataSchema = z.object({\n",
    "  people: z.array(person).describe(\"Extracted data about people\"),\n",
    "});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f887d49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  people: [\n",
      "    { name: 'Jeff', hair_color: 'black', height_in_meters: 1.83 },\n",
      "    { name: 'Anna', hair_color: 'black', height_in_meters: 0 }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "const structured_llm3 = llm.withStructuredOutput(dataSchema);\n",
    "const prompt3 = await promptTemplate.invoke({\n",
    "  text: \"My name is Jeff, my hair is black and i am 6 feet tall. Anna has the same color hair as me.\",\n",
    "});\n",
    "await structured_llm3.invoke(prompt3);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TypeScript",
   "language": "typescript",
   "name": "tslab"
  },
  "language_info": {
   "codemirror_mode": {
    "mode": "typescript",
    "name": "javascript",
    "typescript": true
   },
   "file_extension": ".ts",
   "mimetype": "text/typescript",
   "name": "typescript",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
