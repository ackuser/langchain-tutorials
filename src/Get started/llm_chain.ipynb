{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "518ad7fe",
   "metadata": {},
   "source": [
    "## Using Language Models\n",
    "\n",
    "https://js.langchain.com/docs/tutorials/llm_chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e1c479",
   "metadata": {},
   "source": [
    "#### Load Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d806f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Load environment variables\n",
    "import * as dotenv from \"dotenv\";\n",
    "dotenv.config();\n",
    "\n",
    "if (!process.env.OPENAI_API_KEY) {\n",
    "  throw new Error(\"Missing OPENAI_API_KEY environment variable\");\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439342b2",
   "metadata": {},
   "source": [
    "#### Import LangChain Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd4b8651",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { ChatOpenAI } from \"@langchain/openai\";\n",
    "import { HumanMessage, SystemMessage } from \"@langchain/core/messages\";"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58dac7f",
   "metadata": {},
   "source": [
    "####  Initialize the ChatOpenAI Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5c60165",
   "metadata": {},
   "outputs": [],
   "source": [
    "const model = new ChatOpenAI({ openAIApiKey: process.env.OPENAI_API_KEY, model: \"gpt-4\" });"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2539f3",
   "metadata": {},
   "source": [
    "#### Define the Messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b7f9fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "const messages = [\n",
    "    new SystemMessage(\"Translate the following from English into Italian\"),\n",
    "    new HumanMessage(\"hi!\"),\n",
    "  ];"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8feead5",
   "metadata": {},
   "source": [
    "#### Invoke the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "858a5ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIMessage {\n",
      "  \"id\": \"chatcmpl-BJh9O0gjNVXdQjUJQhifIV0NOkZ7z\",\n",
      "  \"content\": \"ciao!\",\n",
      "  \"additional_kwargs\": {},\n",
      "  \"response_metadata\": {\n",
      "    \"tokenUsage\": {\n",
      "      \"promptTokens\": 20,\n",
      "      \"completionTokens\": 4,\n",
      "      \"totalTokens\": 24\n",
      "    },\n",
      "    \"finish_reason\": \"stop\",\n",
      "    \"model_name\": \"gpt-4-0613\"\n",
      "  },\n",
      "  \"tool_calls\": [],\n",
      "  \"invalid_tool_calls\": [],\n",
      "  \"usage_metadata\": {\n",
      "    \"output_tokens\": 4,\n",
      "    \"input_tokens\": 20,\n",
      "    \"total_tokens\": 24,\n",
      "    \"input_token_details\": {\n",
      "      \"audio\": 0,\n",
      "      \"cache_read\": 0\n",
      "    },\n",
      "    \"output_token_details\": {\n",
      "      \"audio\": 0,\n",
      "      \"reasoning\": 0\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "const response = await model.invoke(messages);\n",
    "console.log(response);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb35128",
   "metadata": {},
   "source": [
    "#### OpenAI format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4e8c461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIMessage {\n",
      "  \"id\": \"chatcmpl-BJhGaVpOwkxVJyBiJVLuFXzkB4gln\",\n",
      "  \"content\": \"Hello! How can I assist you today?\",\n",
      "  \"additional_kwargs\": {},\n",
      "  \"response_metadata\": {\n",
      "    \"tokenUsage\": {\n",
      "      \"promptTokens\": 9,\n",
      "      \"completionTokens\": 10,\n",
      "      \"totalTokens\": 19\n",
      "    },\n",
      "    \"finish_reason\": \"stop\",\n",
      "    \"model_name\": \"gpt-4-0613\"\n",
      "  },\n",
      "  \"tool_calls\": [],\n",
      "  \"invalid_tool_calls\": [],\n",
      "  \"usage_metadata\": {\n",
      "    \"output_tokens\": 10,\n",
      "    \"input_tokens\": 9,\n",
      "    \"total_tokens\": 19,\n",
      "    \"input_token_details\": {\n",
      "      \"audio\": 0,\n",
      "      \"cache_read\": 0\n",
      "    },\n",
      "    \"output_token_details\": {\n",
      "      \"audio\": 0,\n",
      "      \"reasoning\": 0\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "await model.invoke(\"Hello\");\n",
    "\n",
    "await model.invoke([{ role: \"user\", content: \"Hello\" }]);\n",
    "\n",
    "await model.invoke([new HumanMessage(\"hi!\")]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb127a3",
   "metadata": {},
   "source": [
    "#### Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f887d49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|\n",
      "C|\n",
      "iao|\n",
      "!|\n",
      "|\n",
      "|\n"
     ]
    }
   ],
   "source": [
    "const stream = await model.stream(messages);\n",
    "\n",
    "const chunks = [];\n",
    "for await (const chunk of stream) {\n",
    "  chunks.push(chunk);\n",
    "  console.log(`${chunk.content}|`);\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa40e4e2",
   "metadata": {},
   "source": [
    "#### Prompt Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "643d55cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: Translate the following from English into Italian\n",
      "Human: hi!\n",
      "\"System: Translate the following from English into Italian\\nHuman: hi!\"\n",
      "System: Translate the following from English into Italian\n",
      "Human: hi!\n"
     ]
    }
   ],
   "source": [
    "import { ChatPromptTemplate } from \"@langchain/core/prompts\";\n",
    "\n",
    "const systemTemplate = \"Translate the following from English into {language}\";\n",
    "\n",
    "const promptTemplate = ChatPromptTemplate.fromMessages([\n",
    "    [\"system\", systemTemplate],\n",
    "    [\"user\", \"{text}\"],\n",
    "]);\n",
    "\n",
    "const promptValue = await promptTemplate.format({ language: \"Italian\", text: \"hi!\" });\n",
    "\n",
    "// Log the object\n",
    "console.log(promptValue);\n",
    "\n",
    "// Pretty-print the object\n",
    "console.log(JSON.stringify(promptValue, null, 2));\n",
    "\n",
    "// Return the object for Jupyter\n",
    "promptValue;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6cf32c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatPromptValue {\n",
      "  lc_serializable: true,\n",
      "  lc_kwargs: {\n",
      "    messages: [\n",
      "      SystemMessage {\n",
      "        \"content\": \"Translate the following from English into Italian\",\n",
      "        \"additional_kwargs\": {},\n",
      "        \"response_metadata\": {}\n",
      "      },\n",
      "      HumanMessage {\n",
      "        \"content\": \"hi!\",\n",
      "        \"additional_kwargs\": {},\n",
      "        \"response_metadata\": {}\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  lc_namespace: [ 'langchain_core', 'prompt_values' ],\n",
      "  messages: [\n",
      "    SystemMessage {\n",
      "      \"content\": \"Translate the following from English into Italian\",\n",
      "      \"additional_kwargs\": {},\n",
      "      \"response_metadata\": {}\n",
      "    },\n",
      "    HumanMessage {\n",
      "      \"content\": \"hi!\",\n",
      "      \"additional_kwargs\": {},\n",
      "      \"response_metadata\": {}\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "[\n",
      "  SystemMessage {\n",
      "    \"content\": \"Translate the following from English into Italian\",\n",
      "    \"additional_kwargs\": {},\n",
      "    \"response_metadata\": {}\n",
      "  },\n",
      "  HumanMessage {\n",
      "    \"content\": \"hi!\",\n",
      "    \"additional_kwargs\": {},\n",
      "    \"response_metadata\": {}\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import { ChatPromptTemplate } from \"@langchain/core/prompts\";\n",
    "\n",
    "const systemTemplate = \"Translate the following from English into {language}\";\n",
    "const promptTemplate = ChatPromptTemplate.fromMessages([\n",
    "  [\"system\", systemTemplate],\n",
    "  [\"user\", \"{text}\"],\n",
    "]);\n",
    "\n",
    "const promptValue = await promptTemplate.formatPromptValue({\n",
    "  language: \"Italian\",\n",
    "  text: \"hi!\",\n",
    "});\n",
    "\n",
    "promptValue;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8c2a4c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  SystemMessage {\n",
      "    \"content\": \"Translate the following from English into Italian\",\n",
      "    \"additional_kwargs\": {},\n",
      "    \"response_metadata\": {}\n",
      "  },\n",
      "  HumanMessage {\n",
      "    \"content\": \"hi!\",\n",
      "    \"additional_kwargs\": {},\n",
      "    \"response_metadata\": {}\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "const chatMessages = promptValue.toChatMessages();\n",
    "console.log(chatMessages);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b4315958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: ciao!\n"
     ]
    }
   ],
   "source": [
    "const response = await model.invoke(promptValue);\n",
    "console.log(`${response.content}`);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TypeScript",
   "language": "typescript",
   "name": "tslab"
  },
  "language_info": {
   "codemirror_mode": {
    "mode": "typescript",
    "name": "javascript",
    "typescript": true
   },
   "file_extension": ".ts",
   "mimetype": "text/typescript",
   "name": "typescript",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
